# DeepSeek-R1-Distill Model Setup Guide

**Tarih**: 16 AralÄ±k 2025  
**Model**: DeepSeek-R1-Distill-Qwen-7B (Uncensored)  
**Quantization**: Q4_K_M (4-bit, ~4.4 GB)  
**Hardware**: RTX 3060 6GB âœ… Perfect Match!

---

## ğŸ¯ Neden DeepSeek-R1-Distill?

### AvantajlarÄ±:

- âœ… **Uncensored**: Akademik proje iÃ§in etik kÄ±sÄ±tlamalar yok
- âœ… **Advanced Reasoning**: Llama-3.3-70B'den distill edilmiÅŸ, akÄ±llÄ± yanÄ±tlar
- âœ… **HÄ±zlÄ±**: Q4_K_M quantization ile RTX 3060'ta Ã§ok hÄ±zlÄ±
- âœ… **KÃ¼Ã§Ã¼k**: 4.4 GB, SSD'nize sÄ±ÄŸar
- âœ… **TÃ¼rkÃ§e DesteÄŸi**: Qwen tabanlÄ±, Ã§ok dilli
- âœ… **GPU Optimized**: num_gpu=1 ile RTX 3060 kullanÄ±r

### Ã–nceki Modelle KarÅŸÄ±laÅŸtÄ±rma:

| Ã–zellik        | Qwen2:7B (Eski) | DeepSeek-R1-Distill (Yeni) |
|----------------|-----------------|----------------------------|
| Reasoning      | â­â­â­ Orta        | â­â­â­â­â­ MÃ¼kemmel             |
| TÃ¼rkÃ§e         | â­â­â­â­ Ä°yi        | â­â­â­â­â­ Ã‡ok Ä°yi              |
| Censorship     | âŒ Var           | âœ… Yok (Uncensored)         |
| HÄ±z (RTX 3060) | â­â­â­â­ HÄ±zlÄ±      | â­â­â­â­ HÄ±zlÄ±                 |
| Model Boyutu   | 3.8 GB          | 4.4 GB                     |
| YanÄ±t Kalitesi | â­â­â­ Orta        | â­â­â­â­â­ MÃ¼kemmel             |

---

## ğŸ“¥ Kurulum Durumu

### âœ… Otomatik Kurulum (ÅU ANDA Ã‡ALIÅIYOR)

```powershell
cd D:\Projects\SelcukAiAssistant\backend
.\setup_deepseek.ps1
```

**Ä°lerleme:**

1. âœ… Model indiriliyor: `DeepSeek-R1-Distill-Qwen-7B-Q4_K_M.gguf` (~4.4 GB)
2. â³ Modelfile oluÅŸturulacak
3. â³ Ollama modeli create edilecek
4. â³ Test edilecek

**Tahmini SÃ¼re**: 10-15 dakika (High-speed WiFi)

---

## ğŸ”§ Manuel Kurulum (Alternatif)

EÄŸer script baÅŸarÄ±sÄ±z olursa:

### AdÄ±m 1: GGUF DosyasÄ±nÄ± Ä°ndir

**SeÃ§enek A**: HuggingFace'ten direkt indir

```
https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-7B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-7B-Q4_K_M.gguf
```

**SeÃ§enek B**: Git LFS ile

```powershell
git lfs install
git clone https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-7B-GGUF
```

**Ä°ndirme Yeri**: `D:\Projects\SelcukAiAssistant\backend\`

### AdÄ±m 2: Modelfile OluÅŸtur

`backend/Modelfile.deepseek` dosyasÄ± otomatik oluÅŸturuldu âœ…

### AdÄ±m 3: Ollama Modeli OluÅŸtur

```powershell
cd D:\Projects\SelcukAiAssistant\backend
ollama create selcuk_ai_assistant -f Modelfile.deepseek
```

### AdÄ±m 4: Test Et

```powershell
ollama run selcuk_ai_assistant "Merhaba, sen kimsin?"
```

**Beklenen YanÄ±t:**

```
Merhaba! Ben SelÃ§uk AI AsistanÄ±, SelÃ§uk Ãœniversitesi'nin resmi yapay zeka asistanÄ±yÄ±m...
```

---

## ğŸš€ Backend'i BaÅŸlatma

Model kurulumu tamamlandÄ±ktan sonra:

### 1. Backend'i BaÅŸlat

```powershell
cd D:\Projects\SelcukAiAssistant\backend
python main.py
```

**Beklenen Log:**

```
INFO - Ollama service initialized: url=http://localhost:11434/api/generate, model=selcuk_ai_assistant, timeout=120s
INFO - Appwrite client initialized: endpoint=..., project=..., database=..., collection=chat_logs
INFO - Starting server on 0.0.0.0:8000
```

### 2. Flutter UygulamasÄ±nÄ± BaÅŸlat

```powershell
cd D:\Projects\SelcukAiAssistant
flutter run -d chrome
```

### 3. Test SorularÄ±

**Test 1: Basit Soru**

```
"Merhaba"
```

**Beklenen (Ä°yi):**

```
Merhaba! Ben SelÃ§uk AI AsistanÄ±, SelÃ§uk Ãœniversitesi'nin resmi yapay zeka asistanÄ±yÄ±m. 
Size nasÄ±l yardÄ±mcÄ± olabilirim?
```

**Test 2: DetaylÄ± Soru**

```
"SelÃ§uk Ãœniversitesi hakkÄ±nda bilgi ver"
```

**Beklenen (MÃ¼kemmel):**

```
## SelÃ§uk Ãœniversitesi

SelÃ§uk Ãœniversitesi, Konya'da yer alan kÃ¶klÃ¼ bir devlet Ã¼niversitesidir.

**Temel Bilgiler:**
- ğŸ›ï¸ KuruluÅŸ: 1975
- ğŸ“ Åehir: Konya
- ğŸ‘¥ Ã–ÄŸrenci SayÄ±sÄ±: ~80,000
- ğŸ“ FakÃ¼lte SayÄ±sÄ±: 24

**KampÃ¼sler:**
1. **Alaeddin Keykubat KampÃ¼sÃ¼** (Merkez)
2. **SelÃ§uklu KampÃ¼sÃ¼**
3. **Ã‡umra KampÃ¼sÃ¼**

ğŸ“ **Ä°letiÅŸim**: 0332 223 XXXX
ğŸŒ **Web**: selcuk.edu.tr
```

---

## ğŸ” Performans Optimizasyonu

### RTX 3060 6GB iÃ§in Ayarlar:

Modelfile'da zaten optimize edildi:

```
PARAMETER num_gpu 1          # GPU'yu kullan
PARAMETER num_ctx 8192       # Context window (bellek yeterli)
PARAMETER temperature 0.7    # Dengeli yaratÄ±cÄ±lÄ±k
PARAMETER top_p 0.9          # Nucleus sampling
PARAMETER top_k 40           # Top-k sampling
PARAMETER repeat_penalty 1.1 # Tekrar Ã¶nleme
```

### Beklenen Performans:

| Metrik           | DeÄŸer                         |
|------------------|-------------------------------|
| Ä°lk Token SÃ¼resi | ~1-2 saniye                   |
| Token/Saniye     | ~30-40 tokens/s               |
| Ortalama YanÄ±t   | ~5-10 saniye (200 token iÃ§in) |
| GPU KullanÄ±mÄ±    | ~80-90%                       |
| VRAM KullanÄ±mÄ±   | ~4.5 GB / 6 GB                |
| CPU KullanÄ±mÄ±    | Minimal (~10%)                |

---

## ğŸ“Š Sorun Giderme

### Model Ä°ndirmesi Ã‡ok Uzun SÃ¼rÃ¼yor

**Ã‡Ã¶zÃ¼m 1**: FarklÄ± quantization dene (daha kÃ¼Ã§Ã¼k)

```
Q3_K_M: ~3.5 GB (biraz daha hÄ±zlÄ±, biraz daha dÃ¼ÅŸÃ¼k kalite)
Q4_K_M: ~4.4 GB (Ã¶nerilen, dengeli)
Q5_K_M: ~5.3 GB (daha iyi kalite, daha yavaÅŸ)
```

**Ã‡Ã¶zÃ¼m 2**: Torrent ile indir (eÄŸer HuggingFace torrent desteÄŸi varsa)

### Model YanÄ±tlarÄ± HÃ¢lÃ¢ KÃ¶tÃ¼

**Kontrol 1**: DoÄŸru model kullanÄ±lÄ±yor mu?

```powershell
ollama list | Select-String "selcuk"
```

**Kontrol 2**: Backend doÄŸru modeli kullanÄ±yor mu?

```powershell
Get-Content backend\.env | Select-String "OLLAMA_MODEL"
```

**Ã‡Ã¶zÃ¼m**: Backend'i yeniden baÅŸlat

```powershell
taskkill /F /IM python.exe; python backend/main.py
```

### GPU KullanÄ±lmÄ±yor

**Kontrol**: Ollama GPU kullanÄ±mÄ±

```powershell
nvidia-smi
```

**Ã‡Ã¶zÃ¼m**: Modelfile'da `PARAMETER num_gpu 1` var mÄ± kontrol et

### VRAM Yetersiz (Unlikely)

RTX 3060 6GB ile Q4_K_M rahatÃ§a Ã§alÄ±ÅŸÄ±r, ama eÄŸer sorun olursa:

**Ã‡Ã¶zÃ¼m**: Daha kÃ¼Ã§Ã¼k quantization kullan

```
Q3_K_M: ~3.5 GB (VRAM kullanÄ±mÄ± ~3.8 GB)
```

---

## ğŸ“ Model Ã–zellikleri

### DeepSeek-R1-Distill Nedir?

**DeepSeek-R1**: DeepSeek tarafÄ±ndan geliÅŸtirilen, OpenAI o1'e rakip bir reasoning model

**Distill**: Llama-3.3-70B-Instruct'tan kÃ¼Ã§Ã¼ltÃ¼lmÃ¼ÅŸ (70B â†’ 7B/8B)

**Qwen-7B**: Alibaba'nÄ±n Ã§ok dilli (TÃ¼rkÃ§e dahil) base modeli

**Q4_K_M**: 4-bit quantization, hafÄ±za ve hÄ±z iÃ§in optimize

### Uncensored Ne Demek?

- âŒ Etik filtreleme yok
- âŒ "I can't assist with that" yanÄ±tlarÄ± yok
- âœ… Akademik araÅŸtÄ±rma iÃ§in serbestlik
- âœ… Her tÃ¼rlÃ¼ soruya yanÄ±t verebilir
- âš ï¸ **Dikkat**: KÃ¶tÃ¼ye kullanÄ±labilir, sorumlu kullanÄ±n

### Neden Uncensored Gerekli?

Akademik AI asistan projesi iÃ§in:

- SansÃ¼r yanÄ±tlarÄ± engellemez
- Ãœniversite bilgilerini serbestÃ§e paylaÅŸÄ±r
- Test ve geliÅŸtirme iÃ§in daha esnek
- Ãœretim ortamÄ±nda gerekirse custom filtreler eklenebilir

---

## ğŸ“ Sonraki AdÄ±mlar

### 1. Model Ä°ndirmesi TamamlanÄ±nca (10-15 dk)

- [ ] Script bittiÄŸinde "Setup Complete!" gÃ¶receksiniz
- [ ] Backend'i baÅŸlatÄ±n: `python main.py`
- [ ] Flutter'da test edin

### 2. AI YanÄ±t Kalitesini DeÄŸerlendirin

**KarÅŸÄ±laÅŸtÄ±rma:**

- Ã–nceki yanÄ±t: "SelÃ§uk Al AsistanÄ± olsun..." (KÃ¶tÃ¼)
- Yeni yanÄ±t: Markdown, yapÄ±landÄ±rÄ±lmÄ±ÅŸ, profesyonel (Ä°yi)

### 3. Appwrite Logging KontrolÃ¼

Backend loglarÄ±nda:

```
INFO - âœ… Appwrite log kaydÄ± baÅŸarÄ±lÄ±: chat_abc123...
```

Appwrite Console'da Documents tab'Ä±nda yeni kayÄ±tlarÄ± gÃ¶rÃ¼n.

### 4. Fine-tuning (Gelecek)

Daha da iyi yanÄ±tlar iÃ§in:

- SelÃ§uk Ãœniversitesi dÃ¶kÃ¼manlarÄ±yla fine-tune
- RAG (Retrieval-Augmented Generation) ekle
- Custom prompts optimize et

---

## ğŸ”— Kaynaklar

- **Model**: https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-7B-GGUF
- **DeepSeek-R1 Paper**: https://github.com/deepseek-ai/DeepSeek-R1
- **Ollama Docs**: https://ollama.ai/docs
- **GGUF Format**: https://github.com/ggerganov/llama.cpp

---

## âœ… Checklist

Model kurulumu iÃ§in:

- [ ] Model indirmesi tamamlandÄ± (~4.4 GB)
- [ ] Modelfile.deepseek oluÅŸturuldu
- [ ] `ollama create` baÅŸarÄ±lÄ±
- [ ] `ollama run` test edildi
- [ ] Backend baÅŸlatÄ±ldÄ±
- [ ] Flutter uygulamasÄ± test edildi
- [ ] AI yanÄ±tlarÄ± mÃ¼kemmel
- [ ] Appwrite logging Ã§alÄ±ÅŸÄ±yor

---

**Kurulum tamamlandÄ±ÄŸÄ±nda bu dokÃ¼mantasyonu README'ye ekleyebilirsiniz!** ğŸš€


# ============================================================================
# SelcukAiAssistant Backend Configuration
# ============================================================================
# Copy this file to .env and adjust values as needed
# ============================================================================

# ----------------------------------------------------------------------------
# Server Configuration
# ----------------------------------------------------------------------------
# Host to bind the server to
# - Use 127.0.0.1 for localhost only (recommended for development)
# - Use 0.0.0.0 to allow external connections
HOST=127.0.0.1

# Port number for the server (1-65535)
PORT=8000

# ----------------------------------------------------------------------------
# CORS Configuration
# ----------------------------------------------------------------------------
# Comma-separated list of allowed origins for CORS
# - Use * to allow all origins (only for development!)
# - In production, specify exact URLs: http://localhost:3000,https://app.example.com
ALLOWED_ORIGINS=*

# ----------------------------------------------------------------------------
# Ollama Configuration
# ----------------------------------------------------------------------------
# Base URL of the Ollama service
OLLAMA_BASE_URL=http://localhost:11434

# Model name to use (without :latest tag, it will be handled automatically)
# For this project, use: selcuk_ai_assistant
# Default fallback: llama3.1
OLLAMA_MODEL=selcuk_ai_assistant

# Request timeout in seconds
OLLAMA_TIMEOUT=120

# Maximum number of retry attempts for failed requests
OLLAMA_MAX_RETRIES=3

# Delay between retries in seconds (exponential backoff)
OLLAMA_RETRY_DELAY=1.0

# ----------------------------------------------------------------------------
# Logging Configuration
# ----------------------------------------------------------------------------
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# - DEBUG: Detailed information for debugging
# - INFO: General informational messages (recommended)
# - WARNING: Warning messages
# - ERROR: Error messages only
LOG_LEVEL=INFO

# ----------------------------------------------------------------------------
# RAG (Retrieval-Augmented Generation) Configuration
# ----------------------------------------------------------------------------
# Enable RAG for context-aware responses (true/false)
# Set to false until vector database is set up
RAG_ENABLED=false

# Path to ChromaDB vector database storage
# Example: ./data/chromadb or /var/lib/selcuk-ai/vectordb
RAG_VECTOR_DB_PATH=./data/chromadb

# Collection name in the vector database
RAG_COLLECTION_NAME=selcuk_documents

# Document chunk size for RAG ingestion (in characters)
RAG_CHUNK_SIZE=500

# Overlap between document chunks (in characters)
RAG_CHUNK_OVERLAP=50

# ----------------------------------------------------------------------------
# Rate Limiting (Future Implementation)
# ----------------------------------------------------------------------------
# These are placeholders for future rate limiting implementation
# RATE_LIMIT_ENABLED=false
# RATE_LIMIT_REQUESTS_PER_MINUTE=60
# RATE_LIMIT_REQUESTS_PER_HOUR=1000

# ----------------------------------------------------------------------------
# Security (Future Implementation)
# ----------------------------------------------------------------------------
# These are placeholders for future authentication/security features
# API_KEY_REQUIRED=false
# API_KEY=your-secret-api-key-here
# JWT_SECRET=your-jwt-secret-here
